%------------------------------------------------------------------------------

\subsection{Performance Characterization}

...


\subsubsection{Weak Scaling Experiments}

%We previously demonstrated weak scaling of the ESMACS protocol in [ref SC] where we showed that a single ESMACS instance could run up to 128 concurrent pipelines.
%\jhanote{1 sentence about how pipelines in ESMACS were simpler than TIES? else the
%reader will say: you did 128 pipelines already... why should I be impressed by a
%small number of pipelines. Important to highlight that the scalability is over
%PROTOCOL INSTANCES and not pipeline instances.} \jdnote{added blurb in
%design \& implementation, removed it from here}

Here we show weak scalability for the TIES protocol by growing the number of
protocol instances while adhering to the required number of pipelines. By
design of each protocol, an increase in the number of instances simply means
an increase in the number of pipelines. Therefore our previous ESMACS
experiments~\cite{} \jhanote{fix please} demonstrates the scalability of
ESMACS as a growth in the number of pipelines.

The first weak scalability experiment demonstrates the behavior of HTBAC, EnTK
and RP using the multiple instances of the TIES protocol. By design of weak
scaling, the ratio between the number of pipelines and cores are kept
constant. As the number of cores (measure of resource) changes by a factor of
2, we introduce twice as many protocol instances. As designed, the weak
scaling property provides insight into the size of the workload that can be
investigated in a given amount of time.


% The goal is to isolate and understand the impact of
% increasing the number of instances, thereby the execution workload.



%The next weak scalability experiment replicates the design of the first experiment using a combination of TIES and ESMACS instances. The comparison of experiment 1 and 2 shows the ability to execute procotols with different resource requirements using one pilot.

\subsubsection {Strong Scaling Experiments}

Next we repeat the same design of the weak scalability
experiments but examine performance of strong scaling when fixing the number of
pipelines and varying the resources. The comparison between weak and strong
scalability demonstrates the overhead introduced by load balancing and
scheduling tasks in multiple generations.


\subsection{Validation experiments}

HTBAC fully automates the process of calculating the binding affinity of
protein-ligand complexes from reading the input all the way to analyising the
final results. In order to validate the correctness of the results, we have
devised a set of experiments. These experiments are vital to gain confidence
in the algorithm and to prove that it is indeed calculating the correct values.

The validation experiments were based on the original study of Wan et. al.
\cite{Wan2017brd4}. We selected a subset of the protein ligand systems that
were the subject of that study: they are the ligand transformations 3 to 1, 4,
and 7. We then performed a full simulation on all 3 systems and calculated the
binding affinity (see Table~\ref{tab:exp2}) using HTBAC.

The results show that all three $\Delta \Delta G$ values are within error bars
of the original study, reinforcing the fact that HTBAC has indeed correctly
implemented the complex workflow of TIES.

\begin{table}
  \centering
  \begin{tabular}{l@{\hskip 1in}r@{\hskip 0.2in}r@{\hskip 0.2in}r}
    \toprule
    System & HTBAC & Wan et. al & Experiment \\
    \midrule
    BRD4 \textbf{3 to 1} & \num{0.39 +- 0.10} &   \num{0.4 +- 0.20} &  \num{0.3 +- 0.09} \\
    BRD4 \textbf{3 to 4} & \num{0.02 +- 0.12} &   \num{0.0 +- 0.20} &  \num{0.0 +- 0.13} \\
    BRD4 \textbf{3 to 7} & \num{-1.6 +- 0.17} &  \num{-1.5 +- 0.20} & \num{-1.3 +- 0.11} \\
    \bottomrule
  \end{tabular}

  \caption{Comparison of the calculated binding free energies using HTBAC, from
  the original study by Wan et. al and experimental data. The two theoretical
  studies used the same protcol in principle. This experiment proved that HTBAC
  has indeed implemented TIES correctly, as the calculated values are either
  the same or within error bar of the original study. All values are in
  \textbf{kcal mol\textsuperscript{-1}}.}
  \label{tab:exp2}


\end{table}

%------------------------------------------------------------------------------

\section{Adaptive quadrature in action}



\begin{figure}
\begin{tikzpicture}
\begin{axis}[
  xlabel=$\lambda$,
  ylabel=$\frac{dU}{d\lambda}$,
  xmin=0,
  xmax=1,
  legend pos=outer north east,
  grid=both,
  ]
  \addplot+[name path=alch_1, mark size=1pt, mark=*, color=blue] table [x=lambda, y=p1v]{figures/alch_1.csv};
  \addlegendentry{Iteration 0: inital lambda spacing};

  \addplot+[name path=alch_2, mark size=1pt, mark=*, color=red] table [x=lambda, y=p1v]{figures/alch_2.csv};
  \addlegendentry{Iteration 1: Increasing number of lambda values};

  \addplot+[name path=alch_3, mark size=1pt, mark=*, color=brown] table [x=lambda, y=p1v]{figures/alch_3.csv};
  \addlegendentry{Iteration 2: Optimial number of lambda values found};

  \addplot+[name path=alch_4, mark size=1pt, mark=*, color=black] table [x=lambda, y=p1v]{figures/alch_4.csv};
  \addlegendentry{Iteration 3: Refining function values at optimial mesh};

  \addplot[name path=line, draw=none] {0};

  \addplot fill between[
    of = alch_1 and line,
    split,
    every even segment/.style = {pattern color=blue!50, pattern=vertical lines},
    every odd segment/.style = {pattern color=blue!50, pattern=vertical lines},
    soft clip={domain=0:1},
  ];

  \addplot fill between[
    of = alch_2 and line,
    split,
    every even segment/.style = {pattern color=red!50, pattern=horizontal lines},
    every odd segment/.style = {pattern color=red!50, pattern=horizontal lines},
    soft clip={domain=0:1},
  ];

  \addplot fill between[
    of = alch_3 and line,
    split,
    every even segment/.style = {pattern color=brown!50, pattern=north east lines},
    every odd segment/.style = {pattern color=brown!50, pattern=north east lines},
    soft clip={domain=0:1},
  ];

\end{axis}
\end{tikzpicture}
\caption{The adaptive algorithm reevaluates the efficiency of the lambda window mesh after every \SI{1}{\nano\second} and makes a decision whether to place more lambda windows inside certain ranges. The decision of placing more lambda windows in a range $[\lambda_{i}; \lambda_{j}]$ is based on the following criterion: $|f(\lambda_{i})-f(\lambda_{j})| \leq h$ where $h$ is some threshold set by the user. Once the optimal mesh is reached, and no more lambda windows are needed, the algorithm runs the simulation for a further \SI{2}{\nano\second} to converge the results.}
\label{fig:adapt}
\end{figure}
